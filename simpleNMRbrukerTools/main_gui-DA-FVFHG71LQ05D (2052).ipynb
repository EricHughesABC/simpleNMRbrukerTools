{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1ef57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff4f7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import socket\n",
    "import requests\n",
    "import webbrowser\n",
    "from typing import Dict, List, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4707ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bruker.api.topspin import Topspin\n",
    "from bruker.data.nmr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3003d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import simpleNMRbrukerTools\n",
    "print(simpleNMRbrukerTools.__version__)\n",
    "\n",
    "# Import submodules\n",
    "from simpleNMRbrukerTools import core\n",
    "from simpleNMRbrukerTools import gui\n",
    "from simpleNMRbrukerTools import parsers\n",
    "from simpleNMRbrukerTools import utils\n",
    "\n",
    "from simpleNMRbrukerTools.core.json_converter import BrukerToJSONConverter\n",
    "from simpleNMRbrukerTools.core.data_reader import BrukerDataDirectory  \n",
    "from simpleNMRbrukerTools.config import EXPERIMENT_CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79912a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIDATA imports\n",
    "try:\n",
    "    import guidata\n",
    "    import guidata.dataset as gds\n",
    "    import guidata.dataset.dataitems as gdi\n",
    "    from guidata.dataset.datatypes import DataSet\n",
    "    from guidata.dataset.dataitems import DirectoryItem\n",
    "    GUIDATA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Error: GUIDATA not available. Please install guidata:\")\n",
    "    print(\"pip install guidata\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if GUIDATA_AVAILABLE:\n",
    "    # import local guidataWarningDialogs\n",
    "    from simpleNMRbrukerTools.gui.guidataWarningDialogs import WarningDialog, myGUIDATAwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e7997c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bruker_root_folder_from_identifier(path):\n",
    "    \"\"\"\n",
    "    Check if 'pdata' is in the path, and return the path up to the parent of pdata's parent-1.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    parts = path.parts\n",
    "    \n",
    "    if 'pdata' in parts:\n",
    "        pdata_index = parts.index('pdata')\n",
    "        # Go back one more level (skip the parent of pdata too)\n",
    "        return Path(*parts[:pdata_index-1])\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e8bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bruker.data.nmr.NMRDataSet,\n",
       " bruker.api.topspin.DataProvider,\n",
       " bruker.api.topspin.Topspin)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a31f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b95db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a558ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ebfda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1bb1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrukerFolderDialog(DataSet):\n",
    "    \"\"\"Dialog for selecting Bruker experiment folder.\"\"\"\n",
    "    bruker_folder = DirectoryItem(\"Bruker Data Folder\", default=\".\")\n",
    "\n",
    "\n",
    "def create_processing_class(expt_pdata_with_peaks, converter):\n",
    "    class Processing(gds.DataSet):\n",
    "        \"\"\"Example\"\"\"\n",
    "        \n",
    "        expts = {}\n",
    "        \n",
    "        for expt_id, proc_files in expt_pdata_with_peaks.items():\n",
    "            expt_data = converter.bruker_data[expt_id]\n",
    "            experiment_type = expt_data.get('experimentType', 'Unknown')\n",
    "            if experiment_type == \"Unknown\":\n",
    "                continue\n",
    "            \n",
    "            procnumbers = [proc_file.name for proc_file in proc_files]\n",
    "            procnumbers.append(\"SKIP\")\n",
    "            print(expt_id, procnumbers)\n",
    "            \n",
    "            expts[f\"expt_{expt_id}\"] = (gdi.ChoiceItem(f\"{expt_id} {experiment_type}\", procnumbers))\n",
    "            locals()[f\"expt_{expt_id}\"] = expts[f\"expt_{expt_id}\"]\n",
    "\n",
    "        simulated_annealing = gdi.BoolItem(\"Use simulated annealing\", default=True)\n",
    "        ml_consent = gdi.BoolItem(\"Permit Data to be saved to build Database\", default=False)\n",
    "    \n",
    "    return Processing\n",
    "\n",
    "def create_processing_dialog(experiments_with_peaks: Dict[str, List], converter):\n",
    "    \"\"\"\n",
    "    Dynamically create a processing dialog based on available experiments.\n",
    "    \n",
    "    Args:\n",
    "        experiments_with_peaks: Dictionary mapping experiment IDs to available processing folders\n",
    "        converter: BrukerToJSONConverter instance\n",
    "        \n",
    "    Returns:\n",
    "        DataSet class for the processing dialog\n",
    "    \"\"\"\n",
    "    class Processing(gds.DataSet):\n",
    "        \"\"\"Example\"\"\"\n",
    "        \n",
    "        _experiment_choices = {}\n",
    "        \n",
    "        for expt_id, proc_files in experiments_with_peaks.items():\n",
    "            expt_data = converter.bruker_data[expt_id]\n",
    "            experiment_type = expt_data.get('experimentType', 'Unknown')\n",
    "            if experiment_type == \"Unknown\":\n",
    "                continue\n",
    "            \n",
    "            procnumbers = [proc_file.name for proc_file in proc_files]\n",
    "            procnumbers.append(\"SKIP\")\n",
    "            print(expt_id, procnumbers)\n",
    "\n",
    "            _experiment_choices[f\"expt_{expt_id}\"] = (gdi.ChoiceItem(f\"{expt_id} {experiment_type}\", procnumbers))\n",
    "            locals()[f\"expt_{expt_id}\"] = _experiment_choices[f\"expt_{expt_id}\"]\n",
    "\n",
    "        simulated_annealing = gdi.BoolItem(\"Use simulated annealing\", \n",
    "                                           default=True,\n",
    "                                           help=\"Enable simulated annealing of COSY and HMBC for structure optimization\")\n",
    "        ml_consent = gdi.BoolItem(\"Permit Data to be saved to build Database\", \n",
    "                                  default=False,\n",
    "                                  help=\"Allow your data to contribute to improving NMR prediction models\")\n",
    "    \n",
    "    return Processing\n",
    " \n",
    "\n",
    "\n",
    "def check_user_registration() -> bool:\n",
    "    \"\"\"\n",
    "    Check if the user's machine is registered for the service.\n",
    "    \n",
    "    Returns:\n",
    "        True if user can proceed, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate machine ID (MAC address based)\n",
    "        mac_based_id = hex(uuid.getnode())\n",
    "        print(f\"Machine ID: {mac_based_id}\")\n",
    "        \n",
    "        # Prepare request\n",
    "        json_obj = {\"hostname\": mac_based_id}\n",
    "        entry_point = \"https://test-simplenmr.pythonanywhere.com/check_machine_learning\"\n",
    "        \n",
    "        print(\"Checking user registration...\")\n",
    "        \n",
    "        # Make the POST request\n",
    "        response = requests.post(\n",
    "            entry_point,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            json=json_obj,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        print(f\"Registration check response: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                response_data = response.json()\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Invalid JSON response from server.\")\n",
    "                myGUIDATAwarn(\"Invalid JSON response from server.\")\n",
    "                return False\n",
    "            \n",
    "            status = response_data.get(\"status\", False)\n",
    "            \n",
    "            if isinstance(status, str) and status.strip().lower() == \"unregistered\":\n",
    "                print(\"Machine is unregistered. Opening registration page...\")\n",
    "                registration_url = response_data.get(\"registration_url\", \"\")\n",
    "                if registration_url:\n",
    "                    webbrowser.open(registration_url)\n",
    "                else:\n",
    "                    print(\"No registration URL provided.\")\n",
    "                myGUIDATAwarn(\"No registration URL provided.\")\n",
    "                return False\n",
    "            \n",
    "            elif isinstance(status, str) and status.strip().lower() == \"registered\":\n",
    "                print(\"Machine is registered. Proceeding...\")\n",
    "                return True\n",
    "            \n",
    "            elif isinstance(status, bool) and not status:\n",
    "                print(\"Registration status unclear.\")\n",
    "                myGUIDATAwarn(\"Registration status unclear.\")\n",
    "                return False\n",
    "            \n",
    "        else:\n",
    "            print(f\"Registration check failed: {response.status_code} - {response.text}\")\n",
    "            myGUIDATAwarn(f\"Registration check failed: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Network error during registration check: {e}\")\n",
    "        print(\"Proceeding without registration check...\")\n",
    "        myGUIDATAwarn(\"Network error during registration check. Proceeding without registration check.\")\n",
    "        return True  # Allow offline usage\n",
    "    except Exception as e:\n",
    "        print(f\"Error during registration check: {e}\")\n",
    "        myGUIDATAwarn(f\"Error during registration check: {e}\")\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "def find_experiments_with_peaks(converter) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Find experiments that have peak data available.\n",
    "    \n",
    "    Args:\n",
    "        converter: BrukerToJSONConverter instance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping experiment IDs to lists of processing folders with peaks\n",
    "    \"\"\"\n",
    "    experiments_with_peaks = {}\n",
    "    \n",
    "    # Handle both original and refactored data structures\n",
    "    if hasattr(converter, 'bruker_data'):\n",
    "        # Refactored structure\n",
    "        data_dict = converter.bruker_data.data if hasattr(converter.bruker_data, 'data') else converter.bruker_data\n",
    "    else:\n",
    "        # Original structure\n",
    "        data_dict = converter._all_bruker_folders\n",
    "    \n",
    "    for expt_id, expt_data in data_dict.items():\n",
    "        if not expt_data.get('haspeaks', False):\n",
    "            continue\n",
    "            \n",
    "        experiment_type = expt_data.get('experimentType', 'Unknown')\n",
    "        if experiment_type == 'Unknown':\n",
    "            continue\n",
    "        \n",
    "        # Find processing folders with peaks\n",
    "        pdata = expt_data.get('pdata', {})\n",
    "        proc_folders_with_peaks = []\n",
    "        \n",
    "        # Handle different pdata structures\n",
    "        if 'procfolders' in pdata:\n",
    "            # Refactored structure\n",
    "            for folder in pdata.get('procfolders', []):\n",
    "                folder_name = folder.name if hasattr(folder, 'name') else str(folder)\n",
    "                proc_data = pdata.get(folder_name, {})\n",
    "                \n",
    "                if proc_data.get('haspeaks', False):\n",
    "                    proc_folders_with_peaks.append(folder)\n",
    "        else:\n",
    "            # Original structure - check for numbered folders\n",
    "            for key, value in pdata.items():\n",
    "                if key != 'path' and isinstance(value, dict):\n",
    "                    if value.get('haspeaks', False):\n",
    "                        proc_folders_with_peaks.append(key)\n",
    "        \n",
    "        if proc_folders_with_peaks:\n",
    "            experiments_with_peaks[expt_id] = proc_folders_with_peaks\n",
    "            print(f\"Found experiment {expt_id} ({experiment_type}) with {len(proc_folders_with_peaks)} processed datasets\")\n",
    "    \n",
    "    return experiments_with_peaks\n",
    "\n",
    "\n",
    "def process_user_selections(dialog_instance, experiments_with_peaks: Dict, converter) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Process user selections from the dialog.\n",
    "    \n",
    "    Args:\n",
    "        dialog_instance: Instance of the ProcessingDialog\n",
    "        experiments_with_peaks: Available experiments\n",
    "        converter: BrukerToJSONConverter instance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of user selections for conversion\n",
    "    \"\"\"\n",
    "    user_selections = {}\n",
    "    \n",
    "    # Handle both data structures\n",
    "    if hasattr(converter, 'bruker_data'):\n",
    "        data_dict = converter.bruker_data.data if hasattr(converter.bruker_data, 'data') else converter.bruker_data\n",
    "    else:\n",
    "        data_dict = converter._all_bruker_folders\n",
    "    \n",
    "    for expt_id in experiments_with_peaks.keys():\n",
    "        expt_data = data_dict[expt_id]\n",
    "        experiment_type = expt_data.get('experimentType', 'Unknown')\n",
    "        \n",
    "        if experiment_type == \"Unknown\":\n",
    "            continue\n",
    "        \n",
    "        attr_name = f\"expt_{expt_id}\"\n",
    "        if hasattr(dialog_instance, attr_name):\n",
    "            selected_index = getattr(dialog_instance, attr_name)\n",
    "            \n",
    "            # Get the choice item to access the options\n",
    "            choice_item = dialog_instance._experiment_choices[attr_name]\n",
    "            choices = choice_item.get_prop(\"data\", \"choices\")\n",
    "            \n",
    "            # Convert index to actual choice text\n",
    "            if 0 <= selected_index < len(choices):\n",
    "                selected_choice = choices[selected_index][1]  # choices is list of (value, label) tuples\n",
    "                \n",
    "                print(f\"User selected: {expt_id} ({experiment_type}) -> {selected_choice}\")\n",
    "                \n",
    "                if selected_choice != \"SKIP\":\n",
    "                    user_selections[expt_id] = {\n",
    "                        \"experimentType\": experiment_type,\n",
    "                        \"procno\": selected_choice\n",
    "                    }\n",
    "    \n",
    "    return user_selections\n",
    "\n",
    "\n",
    "def submit_to_server(json_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Submit the JSON data to the processing server.\n",
    "    \n",
    "    Args:\n",
    "        json_data: The converted JSON data\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Submitting data to processing server...\")\n",
    "        \n",
    "        response = requests.post(\n",
    "            'https://test-simplenmr.pythonanywhere.com/simpleMNOVA',\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            json=json_data,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        print(f\"Server response: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Save response to file\n",
    "            with open('nmr_analysis_result.html', 'w', encoding='utf-8') as f:\n",
    "                f.write(response.text)\n",
    "            \n",
    "            print(\"✓ Analysis complete! Results saved to 'nmr_analysis_result.html'\")\n",
    "            \n",
    "            # Open in browser\n",
    "            result_path = Path('nmr_analysis_result.html').absolute()\n",
    "            webbrowser.open(f'file://{result_path}')\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Server error: {response.status_code} - {response.text}\")\n",
    "            return False\n",
    "            \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Network error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error submitting to server: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "791387ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QApplication for GUIDATA\n",
    "_app = guidata.qapplication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1ea5a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bruker.data.nmr.NMRDataSet,\n",
       " bruker.api.topspin.DataProvider,\n",
       " bruker.api.topspin.Topspin)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Topspin()\n",
    "dp = top.getDataProvider()\n",
    "cdataset = dp.getCurrentDataset()\n",
    "type(cdataset), type(dp), type(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5754dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brukerRootFolder = Path()\n",
    "if isinstance(cdataset, type(None)):\n",
    "    print(\"Please load a data set that you are working on into Topspin\")\n",
    "else:\n",
    "    brukerRootFolder = get_bruker_root_folder_from_identifier(cdataset.getIdentifier())\n",
    "    bruker_expt_folder = get_bruker_root_folder_from_identifier(cdataset.getIdentifier())\n",
    "    \n",
    "brukerRootFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbf3a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(brukerRootFolder, type(None)):\n",
    "    print(\"No valid Bruker root folder found. Loading default folder for now.\")\n",
    "    if platform.system() == \"Windows\":\n",
    "        bruker_expt_folder = Path(r\"C:\\Users\\vsmw51\\OneDrive - Durham University\\projects\\programming\\2025\\python\\awh\\bruker_data_sets\\E72507_04164043_propyl_benzoate\\04164043\")\n",
    "    if platform.system() == \"Darwin\":\n",
    "        bruker_expt_folder = Path(\"/Users/vsmw51/OneDrive - Durham University/projects/programming/2025/python/awh/bruker_data_sets/E72507_04164043_propyl_benzoate/04164043\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34a0d6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 identified as H1_1D\n",
      "Experiment 4 identified as HMBC\n",
      "Experiment 3 identified as HSQC\n",
      "Experiment 2 identified as COSY\n",
      "Experiment 5 identified as C13_1D\n",
      "Found 1 mol file(s): ['alpha-ionon.mol']\n",
      "Selected mol file: alpha-ionon.mol\n",
      "Successfully loaded mol file: alpha-ionon.mol\n",
      "Molecule has 14 atoms\n",
      "Generated SMILES from mol file: CC(=O)/C=C/C1C(C)=CCCC1(C)C\n"
     ]
    }
   ],
   "source": [
    "converter = BrukerToJSONConverter(bruker_expt_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d154080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine ID: 0x624bb2cbbfd0\n",
      "Checking user registration...\n",
      "Network error during registration check: HTTPSConnectionPool(host='test-simplenmr.pythonanywhere.com', port=443): Read timed out. (read timeout=10)\n",
      "Proceeding without registration check...\n"
     ]
    }
   ],
   "source": [
    "if not check_user_registration():\n",
    "    print(\"\\n❌ Unable to verify registration. Please check your internet connection\")\n",
    "    print(\"   or contact support at simpleNMR@gmail.com for assistance.\")\n",
    "    input(\"Press Enter to exit...\")\n",
    "    myGUIDATAwarn(\"Unable to verify registration. Please check your internet connection or contact support.\")\n",
    "else:\n",
    "    myGUIDATAwarn(\"Registration check passed. Proceeding with data processing...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a8684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2cc875e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select Bruker data folder\n",
    "folder_dialog = BrukerFolderDialog(title=\"Select Bruker Data Folder\")\n",
    "# set default folder\n",
    "folder_dialog.bruker_folder = str(brukerRootFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d5a8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No folder selected. Exiting.\n"
     ]
    }
   ],
   "source": [
    "if not folder_dialog.edit():\n",
    "    print(\"No folder selected. Exiting.\")\n",
    "    myGUIDATAwarn(\"No folder selected. Exiting.\")\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aba1663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected folder: /opt/topspin4.5.0/examdata/exam_CMCse_1\n"
     ]
    }
   ],
   "source": [
    "bruker_data_dir = Path(folder_dialog.bruker_folder)\n",
    "print(f\"Selected folder: {bruker_data_dir}\")\n",
    "\n",
    "if not bruker_data_dir.exists():\n",
    "    # print(f\"❌ Error: Directory does not exist: {bruker_data_dir}\")\n",
    "    myGUIDATAwarn(f\"Error: Directory does not exist: {bruker_data_dir}\")\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbea78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Analyzing Bruker Data...\n",
      "Experiment 1 identified as H1_1D\n",
      "Experiment 4 identified as HMBC\n",
      "Experiment 3 identified as HSQC\n",
      "Experiment 2 identified as COSY\n",
      "Experiment 5 identified as C13_1D\n",
      "Found 1 mol file(s): ['alpha-ionon.mol']\n",
      "Selected mol file: alpha-ionon.mol\n",
      "Successfully loaded mol file: alpha-ionon.mol\n",
      "Molecule has 14 atoms\n",
      "Generated SMILES from mol file: CC(=O)/C=C/C1C(C)=CCCC1(C)C\n",
      "✓ Found 5 experiment folders\n"
     ]
    }
   ],
   "source": [
    "# Load and analyze Bruker data\n",
    "print(\"\\n2. Analyzing Bruker Data...\")\n",
    "try:\n",
    "    converter = BrukerToJSONConverter(bruker_data_dir)\n",
    "    # Handle both data structures\n",
    "    if hasattr(converter, 'bruker_data'):\n",
    "        data_count = len(converter.bruker_data.data if hasattr(converter.bruker_data, 'data') else converter.bruker_data)\n",
    "    else:\n",
    "        data_count = len(converter._all_bruker_folders)\n",
    "    print(f\"✓ Found {data_count} experiment folders\")\n",
    "    myGUIDATAwarn(f\"✓ Found {data_count} experiment folders\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading Bruker data: {e}\")\n",
    "    myGUIDATAwarn(f\"Error loading Bruker data: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e789e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Finding Experiments with Peak Data...\n",
      "Found experiment 3 (HSQC) with 1 processed datasets\n",
      "Found experiment 5 (C13_1D) with 1 processed datasets\n",
      "✓ Found 2 experiments with peak data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Find experiments with peaks\n",
    "print(\"\\n3. Finding Experiments with Peak Data...\")\n",
    "experiments_with_peaks = find_experiments_with_peaks(converter)\n",
    "\n",
    "if not experiments_with_peaks:\n",
    "    print(\"❌ No experiments with peak data found.\")\n",
    "    print(\"   Make sure your data contains processed spectra with peak lists.\")\n",
    "    myGUIDATAwarn(\"No experiments with peak data found.\\n   Make sure your data contains processed spectra with peak lists.\")\n",
    "    # return\n",
    "\n",
    "print(f\"✓ Found {len(experiments_with_peaks)} experiments with peak data\")\n",
    "myGUIDATAwarn(f\"✓ Found {len(experiments_with_peaks)} experiments with peak data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7539f6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/3/pdata/1')], [PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata/1')]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_with_peaks.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c9b3289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HSQC experiment in  3 with 1 processing folders\n"
     ]
    }
   ],
   "source": [
    "# check if HSQC is one of the experiments with peaks\n",
    "hsqc_with_peaks = False\n",
    "for expt_id, proc_folders in experiments_with_peaks.items():\n",
    "    # find id in coverter\n",
    "    expt = converter.bruker_data[expt_id]\n",
    "    if expt[\"experimentType\"] == \"HSQC\":\n",
    "        print(f\"Found HSQC experiment in  {expt_id} with {len(proc_folders)} processing folders\")\n",
    "        hsqc_with_peaks = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98d13aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5'),\n",
       " 'dimensions': 1,\n",
       " 'acqu_files': [PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/acqu'),\n",
       "  PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/acqus')],\n",
       " 'acqu': <simpleNMRbrukerTools.parsers.parameter_parser.BrukerParameterFile at 0x1898aac30>,\n",
       " 'acqus': <simpleNMRbrukerTools.parsers.parameter_parser.BrukerParameterFile at 0x1898aaed0>,\n",
       " 'pulseprogram': 'zgpg30',\n",
       " 'nuclei': ['13C'],\n",
       " 'pdata': {'path': PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata'),\n",
       "  'procfolders': [PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata/1')],\n",
       "  '1': {'path': PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata/1'),\n",
       "   'proc_files': [PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata/1/proc'),\n",
       "    PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata/1/procs')],\n",
       "   'proc': <simpleNMRbrukerTools.parsers.parameter_parser.BrukerParameterFile at 0x1898aaf90>,\n",
       "   'procs': <simpleNMRbrukerTools.parsers.parameter_parser.BrukerParameterFile at 0x1898ab290>,\n",
       "   'peaklist':            ppm  intensity  type annotation\n",
       "   0   198.348140   42.31945     0           \n",
       "   1   148.952330  116.06880     0           \n",
       "   2   132.296723  184.47660     0           \n",
       "   3   131.866118   89.51861     0           \n",
       "   4   122.618058  182.60870     0           \n",
       "   5    54.258628  169.70790     0           \n",
       "   6    32.463689  136.59270     0           \n",
       "   7    31.178288  159.99330     0           \n",
       "   8    27.744082  172.07360     0           \n",
       "   9    26.886047  162.61100     0           \n",
       "   10   26.750731  191.35340     0           \n",
       "   11   22.965504  200.00000     0           \n",
       "   12   22.715037  188.46930     0           ,\n",
       "   'haspeaks': True}},\n",
       " 'experimentType': 'C13_1D',\n",
       " 'peaklist':            ppm  intensity  type annotation\n",
       " 0   198.348140   42.31945     0           \n",
       " 1   148.952330  116.06880     0           \n",
       " 2   132.296723  184.47660     0           \n",
       " 3   131.866118   89.51861     0           \n",
       " 4   122.618058  182.60870     0           \n",
       " 5    54.258628  169.70790     0           \n",
       " 6    32.463689  136.59270     0           \n",
       " 7    31.178288  159.99330     0           \n",
       " 8    27.744082  172.07360     0           \n",
       " 9    26.886047  162.61100     0           \n",
       " 10   26.750731  191.35340     0           \n",
       " 11   22.965504  200.00000     0           \n",
       " 12   22.715037  188.46930     0           ,\n",
       " 'haspeaks': True}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b37400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': [PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/3/pdata/1')],\n",
       " '5': [PosixPath('/opt/topspin4.5.0/examdata/exam_CMCse_1/5/pdata/1')]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_with_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21775ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Experiment Selection Dialog\n",
      "3 ['1', 'SKIP']\n",
      "5 ['1', 'SKIP']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create and show processing dialog\n",
    "print(\"\\n4. Experiment Selection Dialog\")\n",
    "ProcessingDialog = create_processing_dialog(experiments_with_peaks, converter)\n",
    "dialog_instance = ProcessingDialog()\n",
    "\n",
    "if not dialog_instance.edit():\n",
    "    print(\"Dialog cancelled. Exiting.\")\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88e23720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Processing User Selections...\n",
      "User selected: 3 (HSQC) -> 1\n",
      "User selected: 5 (C13_1D) -> 1\n",
      "✓ Selected 2 experiments for processing\n",
      "  - ML consent: False\n",
      "  - Simulated annealing: True\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Process user selections\n",
    "print(\"\\n5. Processing User Selections...\")\n",
    "user_selections = process_user_selections(dialog_instance, experiments_with_peaks, converter)\n",
    "\n",
    "if not user_selections:\n",
    "    print(\"❌ No experiments selected for processing.\")\n",
    "    myGUIDATAwarn(\"No experiments selected for processing.\")\n",
    "    # return\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f\"✓ Selected {len(user_selections)} experiments for processing\")\n",
    "    myGUIDATAwarn(f\"✓ Selected {len(user_selections)} experiments for processing\")\n",
    "\n",
    "    # Get processing options\n",
    "    ml_consent = dialog_instance.ml_consent\n",
    "    simulated_annealing = dialog_instance.simulated_annealing\n",
    "\n",
    "    print(f\"  - ML consent: {ml_consent}\")\n",
    "    print(f\"  - Simulated annealing: {simulated_annealing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2179d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Converting to JSON...\n",
      "Created atom info from mol file: 14 total atoms, 13 carbon atoms\n",
      "Processing experiment 3 with type HSQC\n",
      "Processing experiment 5 with type C13_1D\n",
      "type(json_data): <class 'dict'>\n",
      "✓ JSON conversion complete\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Convert to JSON\n",
    "print(\"\\n6. Converting to JSON...\")\n",
    "try:\n",
    "    json_data = converter.convert_to_json(\n",
    "        user_expt_selections=user_selections,\n",
    "        ml_consent=ml_consent,\n",
    "        simulated_annealing=simulated_annealing\n",
    "    )\n",
    "    print(\"type(json_data):\", type(json_data))\n",
    "    print(\"✓ JSON conversion complete\")\n",
    "    myGUIDATAwarn(\"✓ JSON conversion complete\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during JSON conversion: {e}\")\n",
    "    myGUIDATAwarn(f\"Error during JSON conversion: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4810aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: /opt/topspin4.5.0/examdata/exam_CMCse_1/exam_CMCse_1_assignments.json\n",
      "✓ JSON file saved: /opt/topspin4.5.0/examdata/exam_CMCse_1/exam_CMCse_1_assignments.json\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save JSON file locally\n",
    "output_filename = converter.data_directory / f\"{converter.data_directory.name}_assignments.json\"\n",
    "try:\n",
    "    converter.save_json(output_filename)\n",
    "    print(f\"✓ JSON file saved: {output_filename}\")\n",
    "    myGUIDATAwarn(f\"✓ JSON file saved: {output_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Warning: Could not save JSON file: {e}\")\n",
    "    myGUIDATAwarn(f\"Warning: Could not save JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ac0d79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib._local.PosixPath"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(converter.data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c51db039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Submitting to Analysis Server...\n",
      "Submitting data to processing server...\n",
      "Server response: 200\n",
      "✓ Analysis complete! Results saved to 'nmr_analysis_result.html'\n",
      "✓ Analysis complete! Check the opened browser window for results.\n",
      "\n",
      "============================================================\n",
      "Processing Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Submit to server for analysis\n",
    "print(\"\\n7. Submitting to Analysis Server...\")\n",
    "if submit_to_server(json_data):\n",
    "    print(\"✓ Analysis complete! Check the opened browser window for results.\")\n",
    "    myGUIDATAwarn(\"✓ Analysis complete! Check the opened browser window for results.\")\n",
    "else:\n",
    "    print(\"⚠️  Server submission failed, but JSON file was saved locally.\")\n",
    "    myGUIDATAwarn(\"Server submission failed, but JSON file was saved locally.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Processing Complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:/Users/vsmw51/OneDrive - Durham University/projects/programming/2025/python/awh/simpleNMRbrukerTools'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[\"workingDirectory\"][\"data\"][\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa02e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[\"workingFilename\"][\"data\"][\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40715a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hostname', 'workingDirectory', 'workingFilename', 'allAtomsInfo', 'carbonAtomsInfo', 'nmrAssignments', 'c13predictions', 'chosenSpectra', 'exptIdentifiers', 'spectraWithPeaks', 'carbonCalcPositionsMethod', 'MNOVAcalcMethod', 'randomizeStart', 'startingTemperature', 'endingTemperature', 'coolingRate', 'numberOfSteps', 'ppmGroupSeparation', 'ml_consent', 'simulatedAnnealing'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cd2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_atom_info',\n",
       " '_add_experiment_settings',\n",
       " '_add_ml_consent',\n",
       " '_add_molecular_info',\n",
       " '_add_nmr_spectra',\n",
       " '_add_processing_parameters',\n",
       " '_add_simulated_annealing',\n",
       " '_add_system_info',\n",
       " '_convert_2d_integrals_to_json',\n",
       " '_convert_peaklist_to_json',\n",
       " '_create_all_atoms_info_from_mol',\n",
       " '_create_carbon_atoms_info_from_mol',\n",
       " '_create_spectrum_entry',\n",
       " '_get_experiment_type_string',\n",
       " '_get_integrals_data',\n",
       " '_get_peaks_data',\n",
       " '_get_probe_info',\n",
       " '_get_spec_frequency',\n",
       " '_get_spectrum_subtype',\n",
       " '_get_temperature',\n",
       " '_process_mol_files',\n",
       " 'bruker_data',\n",
       " 'convert_to_json',\n",
       " 'data_directory',\n",
       " 'find_mol_files',\n",
       " 'generate_smiles_from_mol',\n",
       " 'get_json_string',\n",
       " 'json_data',\n",
       " 'load_mol_file',\n",
       " 'mol_files',\n",
       " 'molfile_content',\n",
       " 'rdkit_mol',\n",
       " 'save_json',\n",
       " 'select_mol_file',\n",
       " 'selected_mol_file',\n",
       " 'smiles']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71786bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: Empty data provided\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    success: bool\n",
    "    value: Optional[any] = None\n",
    "    error: Optional[str] = None\n",
    "\n",
    "def process_data(data):\n",
    "    try:\n",
    "        if not data:\n",
    "            return Result(success=False, error=\"Empty data provided\")\n",
    "        \n",
    "        processed = data # function goes here, e.g., expensive_operation(data)\n",
    "        return Result(success=True, value=processed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return Result(success=False, error=str(e))\n",
    "\n",
    "# Usage\n",
    "my_data = None\n",
    "result = process_data(my_data)\n",
    "if result.success:\n",
    "    print(\"Success:\", result.value)\n",
    "else:\n",
    "    print(\"Failed:\", result.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'error',\n",
       " 'success',\n",
       " 'value']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea57ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Empty data provided'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70596fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(success=False, value=None, error='Empty data provided')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd246673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(success=False, value=None, error='Empty data provided')\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67eba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Result(success=False, value=None, error='Empty data provided')\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350973db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
